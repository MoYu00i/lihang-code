{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbHBROjTsNa8",
        "outputId": "6c2f1116-34bc-4e0a-a6eb-137f363f4aa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn #torch.nn是pytorch中自带的一个函数库，里面包含了神经网络中使用的一些常用函数\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#张量形式的数据\n",
        "x=torch.tensor([[-1.0],  [0.0], [1.0], [2.0], [3.0], [4.0]],dtype=torch.float)\n",
        "y=torch.tensor([[-3.0], [-1.0], [1.0], [3.0], [5.0], [7.0]],dtype=torch.float)\n",
        "print(x)\n",
        "x.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FoAYZ3fv9Y9",
        "outputId": "499297e8-e198-4b4d-cd69-fd41274ad7c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.],\n",
            "        [ 0.],\n",
            "        [ 1.],\n",
            "        [ 2.],\n",
            "        [ 3.],\n",
            "        [ 4.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.Linear（）是用于设置网络中的全连接层的，需要注意的是全连接层的输入与输出都是二维张量，一般形状为[batch_size, size]\n",
        "#torch.nn.Linear的作用是对输入向量进行矩阵的乘积和加法。y=x（A）转置+b。这点类似于全连接神经网络的的隐藏层。\n",
        "#in_feature代表输入神经元的个数。out_feature代表输出神经元的个数。bias为False不参与训练。如果为True则参与训练。\n",
        "'''in_features指的是输入的二维张量的大小，即输入的[batch_size, size]中的size。\n",
        "  out_features指的是输出的二维张量的大小，即输出的二维张量的形状为[batch_size，output_size]，当然，它也代表了该全连接层的神经元个数。\n",
        "  从输入输出的张量的shape角度来理解，相当于一个输入为[batch_size, in_features]的张量变换成了[batch_size, out_features]的输出张量。'''\n",
        "layer1 = nn.Linear(1,1, bias=False)\n",
        "model = nn.Sequential(layer1) # 一个序列容器，用于搭建神经网络的模块被按照被传入构造器的顺序添加到nn.Sequential()容器中。"
      ],
      "metadata": {
        "id": "muIwAHb_-dON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "全连接层（fully connected layers，FC）在整个卷积神经网络中起到“分类器”的作用。如果说卷积层、池化层和激活函数等操作是将原始数据映射到隐层特征空间的话，全连接层则起到将学到的“分布式特征表示”（下面会讲到这个分布式特征）映射到样本标记空间的作用。"
      ],
      "metadata": {
        "id": "M2WughmHLbR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 损失和优化器\n",
        "#损失函数nn.MSELoss（）负责让模型知道它在多大程度上学习了输入和输出之间的关系。优化器（在本例中是SGD）的主要作用是在调整权重时最小化或降低损失值。\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "8EK6aBV8QinC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}